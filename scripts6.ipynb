{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\YANSILIYU\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\YANSILIYU\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "Metrics for Aspect '[CLS]':\n",
      "Accuracy: 0.1005\n",
      "Precision: 0.0056\n",
      "Recall: 1.0000\n",
      "F1 Score: 0.0110\n",
      "\n",
      "Metrics for Aspect 'rapidly':\n",
      "Accuracy: 0.1005\n",
      "Precision: 0.0056\n",
      "Recall: 1.0000\n",
      "F1 Score: 0.0110\n",
      "\n",
      "Metrics for Aspect 'evolving':\n",
      "Accuracy: 0.1005\n",
      "Precision: 0.0056\n",
      "Recall: 1.0000\n",
      "F1 Score: 0.0110\n",
      "\n",
      "Metrics for Aspect 'landscape':\n",
      "Accuracy: 0.1005\n",
      "Precision: 0.0056\n",
      "Recall: 1.0000\n",
      "F1 Score: 0.0110\n",
      "\n",
      "Metrics for Aspect 'technology':\n",
      "Accuracy: 0.1055\n",
      "Precision: 0.0111\n",
      "Recall: 1.0000\n",
      "F1 Score: 0.0220\n",
      "\n",
      "Metrics for Aspect 'artificial':\n",
      "Accuracy: 0.1055\n",
      "Precision: 0.0111\n",
      "Recall: 1.0000\n",
      "F1 Score: 0.0220\n",
      "\n",
      "Metrics for Aspect 'intelligence':\n",
      "Accuracy: 0.1055\n",
      "Precision: 0.0111\n",
      "Recall: 1.0000\n",
      "F1 Score: 0.0220\n",
      "\n",
      "Metrics for Aspect 'ai':\n",
      "Accuracy: 0.1005\n",
      "Precision: 0.0056\n",
      "Recall: 1.0000\n",
      "F1 Score: 0.0110\n",
      "\n",
      "Metrics for Aspect 'continues':\n",
      "Accuracy: 0.1005\n",
      "Precision: 0.0056\n",
      "Recall: 1.0000\n",
      "F1 Score: 0.0110\n",
      "\n",
      "Metrics for Aspect 'red':\n",
      "Accuracy: 0.1005\n",
      "Precision: 0.0056\n",
      "Recall: 1.0000\n",
      "F1 Score: 0.0110\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import spacy\n",
    "\n",
    "# Technology Domain\n",
    "technology_text = \"\"\"\n",
    "In the rapidly evolving landscape of technology, artificial intelligence (AI) continues to redefine the way we interact with machines. From advanced robotics to machine learning algorithms, innovations are reshaping industries. Quantum computing is on the horizon, promising unprecedented processing power, while blockchain technology revolutionizes secure and transparent transactions. As the Internet of Things (IoT) expands, interconnected devices create a seamless web of data, enhancing efficiency and connectivity. Cybersecurity measures are crucial to safeguarding sensitive information in this digital era.\n",
    "\"\"\"\n",
    "\n",
    "# Healthcare Domain\n",
    "healthcare_text = \"\"\"\n",
    "In the realm of healthcare, medical breakthroughs are transforming patient care. Precision medicine tailors treatments to individual genetic profiles, while telemedicine bridges the gap between patients and healthcare providers. Advanced imaging technologies like MRI and CT scans enable accurate diagnostics, and robotic-assisted surgeries enhance precision in the operating room. Biotechnology fuels the development of innovative drugs, while wearable devices track and monitor personal health metrics. Healthcare informatics facilitates seamless data exchange for improved decision-making.\n",
    "\"\"\"\n",
    "\n",
    "# Travel Domain\n",
    "travel_text = \"\"\"\n",
    "The travel industry is undergoing a transformation with the integration of cutting-edge technologies. Online booking platforms streamline travel arrangements, while virtual reality enhances pre-trip experiences. Sustainable travel initiatives promote eco-friendly practices, and smart luggage simplifies the journey. Artificial intelligence assists in personalized travel recommendations, and mobile applications provide real-time updates on flights and accommodations. Autonomous vehicles and smart cities contribute to seamless and efficient transportation experiences.\n",
    "\"\"\"\n",
    "\n",
    "sentence = technology_text + healthcare_text + travel_text\n",
    "\n",
    "technology_nouns_phrases = [\n",
    "    \"Artificial intelligence\",\n",
    "    \"Machine learning\",\n",
    "    \"Robotics\",\n",
    "    \"Quantum computing\",\n",
    "    \"Blockchain technology\",\n",
    "    \"Internet of Things (IoT)\",\n",
    "    \"Cybersecurity\",\n",
    "    \"Data analytics\",\n",
    "    \"Automation\",\n",
    "    \"Augmented reality\"\n",
    "]\n",
    "\n",
    "healthcare_nouns_phrases = [\n",
    "    \"Precision medicine\",\n",
    "    \"Telemedicine\",\n",
    "    \"Medical breakthroughs\",\n",
    "    \"Imaging technologies\",\n",
    "    \"Robotic-assisted surgery\",\n",
    "    \"Biotechnology\",\n",
    "    \"Wearable devices\",\n",
    "    \"Healthcare informatics\",\n",
    "    \"Personalized healthcare\",\n",
    "    \"Health metrics tracking\"\n",
    "]\n",
    "\n",
    "travel_nouns_phrases = [\n",
    "    \"booking platforms\",\n",
    "    \"Virtual reality\",\n",
    "    \"Sustainable travel initiatives\",\n",
    "    \"Smart luggage\",\n",
    "    \"Artificial intelligence in travel\",\n",
    "    \"Mobile applications\",\n",
    "    \"Real-time updates\",\n",
    "    \"Autonomous vehicles\",\n",
    "    \"Smart cities\",\n",
    "    \"Transportation experiences\"\n",
    "]\n",
    "\n",
    "nouns_phrases = (\n",
    "    technology_nouns_phrases +\n",
    "    healthcare_nouns_phrases +\n",
    "    travel_nouns_phrases\n",
    ")\n",
    "\n",
    "# Load the English language model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def remove_stopwords_punctuation(text):\n",
    "    # Process the text using SpaCy\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Filter out stop words and punctuation\n",
    "    filtered_tokens = [token.text for token in doc if not token.is_stop and not token.is_punct]\n",
    "\n",
    "    # Join the filtered tokens back into a string\n",
    "    filtered_text = ' '.join(filtered_tokens)\n",
    "\n",
    "    return filtered_text\n",
    "\n",
    "\n",
    "# Apply the function to the provided text\n",
    "sentence = remove_stopwords_punctuation(sentence)\n",
    "\n",
    "# Tokenize the test sentence\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "tokens = tokenizer.tokenize(tokenizer.decode(tokenizer.encode(sentence)))\n",
    "\n",
    "# Identify test noun chunks\n",
    "noun_phrase = (\n",
    "    technology_nouns_phrases +\n",
    "    healthcare_nouns_phrases +\n",
    "    travel_nouns_phrases\n",
    ")\n",
    "\n",
    "# Convert test noun chunks to token positions\n",
    "phrase_positions = []\n",
    "for chunk in noun_phrase:\n",
    "    chunk_tokens = tokenizer.tokenize(tokenizer.decode(tokenizer.encode(chunk)))\n",
    "    phrase_positions.append([i for i, token in enumerate(tokens) if token in chunk_tokens])\n",
    "\n",
    "# Convert test tokens to IDs\n",
    "input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "phrase_positions_ids = [item for sublist in phrase_positions for item in sublist]\n",
    "\n",
    "# Create a binary label tensor where 1 indicates an aspect and 0 otherwise\n",
    "labels = [1 if i in phrase_positions_ids else 0 for i in range(len(tokens))]\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# Convert input_ids to tensor\n",
    "input_ids = torch.tensor(input_ids).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "# Load pre-trained BERT model\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Extract contextualized embeddings\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids)\n",
    "\n",
    "# Obtain embeddings for each token\n",
    "word_embeddings = outputs.last_hidden_state.squeeze(0)\n",
    "\n",
    "# Define a classification model for aspect identification\n",
    "class AspectClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(AspectClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n",
    "\n",
    "# Instantiate the aspect identification model\n",
    "input_size = word_embeddings.size(1)\n",
    "hidden_size = 256\n",
    "output_size = 1\n",
    "model = AspectClassifier(input_size, hidden_size, output_size)\n",
    "\n",
    "\n",
    "# Save the trained model weights\n",
    "#torch.save(model.state_dict(), 'aspect_model.pth')\n",
    "\n",
    "# Load the trained weights (replace 'path_to_your_model_weights.pth' with your actual file path)\n",
    "model.load_state_dict(torch.load('aspect_model.pth'))\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "with torch.no_grad():\n",
    "    predictions = (model(word_embeddings) > 0.5).float()\n",
    "\n",
    "\n",
    "# Convert predictions and labels to numpy arrays for evaluation metrics\n",
    "predictions_np = predictions.numpy().flatten()\n",
    "labels_np = labels.numpy()\n",
    "\n",
    "\n",
    "# Extract the aspects and probabilities from the test predictions\n",
    "aspects_and_probs = [(tokens[i], predictions_np[i]) for i in range(len(tokens)) if predictions_np[i] == 1]\n",
    "\n",
    "# Sort the aspects based on their probabilities in descending order\n",
    "aspects_and_probs.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Select the top 10 aspects\n",
    "top_10_aspects = aspects_and_probs[:10]\n",
    "\n",
    "# Extract the aspects and probabilities separately\n",
    "top_10_aspects, top_10_probs = zip(*top_10_aspects)\n",
    "\n",
    "# Calculate metrics for each of the top 10 aspects separately\n",
    "for aspect in top_10_aspects:\n",
    "    aspect_positions = [i for i, token in enumerate(tokens) if token == aspect]\n",
    "\n",
    "    # Check if aspect_positions is not empty\n",
    "    if aspect_positions:\n",
    "        aspect_labels = [1 if i in aspect_positions else 0 for i in range(len(tokens))]\n",
    "\n",
    "        aspect_labels_np = torch.tensor(aspect_labels).numpy()\n",
    "\n",
    "        # Extract predictions only for all positions in the original sentence\n",
    "        aspect_predictions_np = predictions_np[:len(tokens)]\n",
    "\n",
    "        aspect_accuracy = accuracy_score(aspect_labels_np, aspect_predictions_np)\n",
    "        aspect_precision = precision_score(aspect_labels_np, aspect_predictions_np)\n",
    "        aspect_recall = recall_score(aspect_labels_np, aspect_predictions_np)\n",
    "        aspect_f1 = f1_score(aspect_labels_np, aspect_predictions_np)\n",
    "\n",
    "        # Print metrics for each aspect\n",
    "        print(f\"\\nMetrics for Aspect '{aspect}':\")\n",
    "        print(f\"Accuracy: {aspect_accuracy:.4f}\")\n",
    "        print(f\"Precision: {aspect_precision:.4f}\")\n",
    "        print(f\"Recall: {aspect_recall:.4f}\")\n",
    "        print(f\"F1 Score: {aspect_f1:.4f}\")\n",
    "    else:\n",
    "        print(f\"\\nAspect '{aspect}' not found in the test sentence.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
